{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as transforms \n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.signal\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import shutil\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 2108 train files and 547 test files\n",
      "Total copy duration: 75.93291974067688 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "class DataSplitter:\n",
    "    def __init__(self, data_dir, bird_name, test_size=0.2):\n",
    "        self.data_dir = data_dir\n",
    "        self.bird_name = bird_name\n",
    "        self.test_size = test_size\n",
    "\n",
    "    def split_data(self, root_dir):  # Add root_dir parameter here\n",
    "        # Get the filenames\n",
    "        filenames = os.listdir(os.path.join(self.data_dir, f\"{self.bird_name}_songs\"))\n",
    "        filenames = [f for f in filenames if f.endswith('.wav')]\n",
    "        \n",
    "        # Generate train and test split\n",
    "        train_files, test_files = train_test_split(filenames, test_size=self.test_size, random_state=42)\n",
    "\n",
    "        # Create directories if they do not exist\n",
    "        train_dir = os.path.join(root_dir, \"train\")  # Use root_dir instead of self.data_dir\n",
    "        test_dir = os.path.join(root_dir, \"test\")  # Use root_dir instead of self.data_dir\n",
    "        os.makedirs(train_dir, exist_ok=True)\n",
    "        os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "        # Copy the files\n",
    "        start = time.time()\n",
    "        num_train_files = self._copy_files(train_files, train_dir)\n",
    "        num_test_files = self._copy_files(test_files, test_dir)\n",
    "        end = time.time()\n",
    "        \n",
    "        print(f\"Copied {num_train_files} train files and {num_test_files} test files\")\n",
    "        print(f\"Total copy duration: {end - start} seconds\")\n",
    "\n",
    "    def _copy_files(self, file_list, target_dir):\n",
    "        count = 0\n",
    "        for f in file_list:\n",
    "            # Check if corresponding npz file exists\n",
    "            src_npz = os.path.join(self.data_dir, f\"{self.bird_name}_data_matrices\", f\"{f}.npz\")\n",
    "            if os.path.exists(src_npz):\n",
    "                # Copy wav file\n",
    "                src = os.path.join(self.data_dir, f\"{self.bird_name}_songs\", f)\n",
    "                dst = os.path.join(target_dir, f)\n",
    "                shutil.copy(src, dst)\n",
    "                \n",
    "                # Copy npz file\n",
    "                dst_npz = os.path.join(target_dir, f\"{f}.npz\")\n",
    "                shutil.copy(src_npz, dst_npz)\n",
    "                count += 1\n",
    "\n",
    "        return count\n",
    "\n",
    "root_dir = \"/home/george-vengrovski/Documents/classifier_test\"\n",
    "data_dir = \"/home/george-vengrovski/Documents/canary_data\"\n",
    "bird_name = \"llb3\"\n",
    "\n",
    "splitter = DataSplitter(data_dir, bird_name)\n",
    "splitter.split_data(root_dir)  # Pass root_dir as an argument here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "# Create a Butterworth highpass filter.\n",
    "def butter_highpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='high', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_highpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_highpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "class SongDataSet(Dataset):\n",
    "    def __init__(self, train_or_test, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.file_dirs = []\n",
    "        self.label_dirs = []\n",
    "        \n",
    "        if train_or_test not in [\"train\", \"test\"]:\n",
    "            raise ValueError(\"train_or_test must be either train or test\")\n",
    "\n",
    "        self.file_dir = os.path.join(self.root_dir, train_or_test)\n",
    "\n",
    "        # Collect all files in the given directories\n",
    "        for file in os.listdir(self.file_dir):\n",
    "            if file.endswith('.wav'):\n",
    "                file_path = os.path.join(self.file_dir, file)\n",
    "                label_path = os.path.join(self.file_dir, f\"{os.path.splitext(file)[0]}.wav.npz\")\n",
    "                if os.path.exists(label_path):\n",
    "                    self.file_dirs.append(file_path)\n",
    "                    self.label_dirs.append(label_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load waveforms and labels\n",
    "        waveform, _ = librosa.load(self.file_dirs[index], sr=36200)  \n",
    "        \n",
    "        # Apply the high-pass filter\n",
    "        waveform = butter_highpass_filter(waveform, cutoff=500, fs=36200)\n",
    "        \n",
    "        # If the waveform's length is less than 1 second, recursively call this function on the next index\n",
    "        if len(waveform) < 36200:  # For 1 second of data at 36200 Hz sample rate\n",
    "            return self.__getitem__(index + 1 if index + 1 < self.__len__() else 0)\n",
    "\n",
    "        label_data = np.load(self.label_dirs[index])\n",
    "        label = label_data['labels']\n",
    "\n",
    "        # Slice the first second of waveform and first 362 labels\n",
    "        waveform = waveform[:36200]\n",
    "        label = label[:,:,:362]\n",
    "\n",
    "        # Convert to torch tensors\n",
    "        waveform = torch.from_numpy(waveform).float()\n",
    "        label = torch.from_numpy(label).long()\n",
    "\n",
    "        return waveform, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_dirs)\n",
    "    \n",
    "data_root = \"/home/george-vengrovski/Documents/classifier_test\"\n",
    "train_dataset = SongDataSet(\"train\", root_dir=data_root)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "test_dataset = SongDataSet(\"test\", root_dir=data_root)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_extractor_dim, hidden_size, num_layers, projection_dim):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        # feature extractor\n",
    "        self.conv1 = nn.Conv1d(1, feature_extractor_dim, kernel_size=10, stride=6)\n",
    "        self.conv2 = nn.Conv1d(feature_extractor_dim, feature_extractor_dim, kernel_size=5, stride=2)\n",
    "        self.conv3 = nn.Conv1d(feature_extractor_dim, feature_extractor_dim, kernel_size=4, stride=2)\n",
    "        self.conv4 = nn.Conv1d(feature_extractor_dim, feature_extractor_dim, kernel_size=3, stride=2)\n",
    "        self.conv5 = nn.Conv1d(feature_extractor_dim, feature_extractor_dim, kernel_size=3, stride=2)\n",
    "        self.conv6 = nn.Conv1d(feature_extractor_dim, feature_extractor_dim, kernel_size=3, stride=1)\n",
    "        self.conv7 = nn.Conv1d(feature_extractor_dim, feature_extractor_dim, kernel_size=2, stride=1)\n",
    "        self.adapatvie_pool = nn.AdaptiveAvgPool1d(362)\n",
    "\n",
    "        # GRU Layer\n",
    "        self.gru = nn.GRU(input_size=feature_extractor_dim, hidden_size=hidden_size, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
    "        self.projection_matrix = nn.Linear(hidden_size*2, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = self.adapatvie_pool(x)\n",
    "\n",
    "        # Reshape for GRU\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # x is the output for each timestep of the GRU while h is the final hidden state\n",
    "        x, h = self.gru(x)\n",
    "        # # x = x.permute(0, 2, 1)\n",
    "        x = self.projection_matrix(x)\n",
    "        # # argmax dim 2 \n",
    "        x = x.squeeze(2)\n",
    "\n",
    "        return x \n",
    "    \n",
    "    def loss(self, predictions, labels):\n",
    "        labels = labels.squeeze(1)\n",
    "\n",
    "        pred_length = predictions.shape[1]\n",
    "\n",
    "        labels = labels[:, :pred_length]\n",
    "        # cross entropy loss\n",
    "        loss = F.cross_entropy(predictions.float(), labels.float())\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda devices:  2\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# get cuda devices\n",
    "devices=torch.cuda.device_count()\n",
    "print(\"cuda devices: \",devices)\n",
    "\n",
    "# set device to 2 \n",
    "device = torch.device( \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 362])\n"
     ]
    }
   ],
   "source": [
    "# Given spoof waveform and converting it to the device\n",
    "spoof_waveform = torch.randn(1, 1, 36200)\n",
    "spoof_waveform = spoof_waveform.to(device)\n",
    "\n",
    "# in one second on of input, there are 362 time bins \n",
    "\n",
    "# Your classifier model (I'm assuming you have it defined already)\n",
    "model = Classifier(feature_extractor_dim=128, hidden_size=128, num_layers=1, projection_dim=1)\n",
    "\n",
    "# Passing the spoof waveform through the model\n",
    "output = model.forward(spoof_waveform)\n",
    "\n",
    "# Printing the shape of the output\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,611,777 trainable parameters\n",
      "torch.Size([1, 1, 36200])\n",
      "torch.Size([1, 362])\n",
      "torch.Size([1, 1, 6674])\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m     total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     51\u001b[0m     num_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> 53\u001b[0m avg_loss \u001b[39m=\u001b[39m total_loss \u001b[39m/\u001b[39;49m num_batches  \u001b[39m# compute average loss\u001b[39;00m\n\u001b[1;32m     54\u001b[0m loss_list\u001b[39m.\u001b[39mappend(avg_loss)\n\u001b[1;32m     55\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mEpoch [\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m], Average Loss: \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, epochs, avg_loss))\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# get a random sample from dataloader\n",
    "\n",
    "waveform, label = next(iter(train_loader))\n",
    "\n",
    "epochs = 100\n",
    "learning_rate = 1e-3\n",
    "max_batches = 150\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "model = Classifier(feature_extractor_dim=256, hidden_size=128, num_layers=1, projection_dim=32).to(device)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0  # reset total loss for each epoch\n",
    "    num_batches = 0  # reset num_batches for each epoch\n",
    "    \n",
    "    for i, (waveform, label) in enumerate(train_loader):\n",
    "        if i >= max_batches:  # only use max_batches batches\n",
    "            break\n",
    "        # move to device\n",
    "        waveform = waveform.unsqueeze(1).to(device)\n",
    "        label = label.to(device)  \n",
    "\n",
    "        print(waveform.shape)\n",
    "\n",
    "        # forward pass\n",
    "        output = model.forward(waveform)\n",
    "        print(output.shape)\n",
    "        print(label.shape)\n",
    "        break\n",
    "\n",
    "        # Compute loss\n",
    "        # loss = model.loss(predictions=output, labels=label)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # accumulate loss\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_loss = total_loss / num_batches  # compute average loss\n",
    "    loss_list.append(avg_loss)\n",
    "    print ('Epoch [{}/{}], Average Loss: {:.4f}'.format(epoch+1, epochs, avg_loss))\n",
    "\n",
    "    # # Save model every 10 epochs\n",
    "    # if (epoch+1) % 10 == 0:\n",
    "    #     torch.save(model.state_dict(), f'hubert_model_epoch_{epoch+1}.pth')\n",
    "\n",
    "# print loss curve\n",
    "plt.plot(loss_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "canary-vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
